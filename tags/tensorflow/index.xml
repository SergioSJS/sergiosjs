<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tensorflow on Sérgio - Portfolio</title>
    <link>https://sergiosjs.github.io/tags/tensorflow/</link>
    <description>Recent content in tensorflow on Sérgio - Portfolio</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Jul 2018 12:41:05 -0500</lastBuildDate>
    
	<atom:link href="https://sergiosjs.github.io/tags/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Reinforcement Learning</title>
      <link>https://sergiosjs.github.io/projects/data_science/ds_rl/</link>
      <pubDate>Wed, 11 Jul 2018 12:41:05 -0500</pubDate>
      
      <guid>https://sergiosjs.github.io/projects/data_science/ds_rl/</guid>
      <description>In this project it was verified my reinforcement learning algorithm and test the deep-q-learning applying in Atari games. Also check the domain adaptation technique in 2 games of Atari 2600, Space Invaders and Demon Attack, games with similar gameplay and style. The goal of creating a generalist model capable of playing more than one game and trying to help it converge more quickly. We noticed that the domain transfer slowed learning but allowed a higher score at the beginning of the training.</description>
    </item>
    
    <item>
      <title>Keras &#43; MNIST</title>
      <link>https://sergiosjs.github.io/projects/data_science/ds_keras_mnist/</link>
      <pubDate>Thu, 24 May 2018 12:41:05 -0500</pubDate>
      
      <guid>https://sergiosjs.github.io/projects/data_science/ds_keras_mnist/</guid>
      <description>A simple test with Keras and MNIST to assess impact by varying hyperparans to predict numerical characteres. The best result can be seen in the image below.</description>
    </item>
    
  </channel>
</rss>